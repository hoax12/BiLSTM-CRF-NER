{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BiLSTM vs. BiLSTM-CRF for Named Entity Recognition on the CoNLL Dataset <br><br>\n",
        "\n",
        "\n",
        "### <b>Paper:</b> BiDirectional-LSTM-CRF Models for Sequence Tagging by Huang et. al.\n",
        "### <b>Dataset:</b> https://www.clips.uantwerpen.be/conll2003/ner/ <br><br>\n"
      ],
      "metadata": {
        "id": "hQ-67bmuPLfs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CA_m6aLGO0fT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "import numpy as np\n",
        "from typing import List, Tuple, Dict\n",
        "import logging\n",
        "import requests\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Dataset Preparation"
      ],
      "metadata": {
        "id": "oduiFkDJS2O9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1) Download CoNLL Dataset"
      ],
      "metadata": {
        "id": "kwXZmAIIS7H_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_conll2003():\n",
        "    # 1) Download the dataset\n",
        "    # 2) Differentiate paths into Train, Validation, and Test\n",
        "\n",
        "    # Links\n",
        "    base_url = \"https://raw.githubusercontent.com/synalp/NER/master/corpus/CoNLL-2003/\"\n",
        "    files = ['eng.train', 'eng.testa', 'eng.testb']\n",
        "\n",
        "    # Create directory if it doesnt exist\n",
        "    if not os.path.exists('data'):\n",
        "        os.makedirs(\"data\")\n",
        "\n",
        "    # Download files\n",
        "    file_paths = []\n",
        "    for file in files:\n",
        "        path = f\"data/{file}\"\n",
        "        file_paths.append(path)\n",
        "\n",
        "        if os.path.exists(path):\n",
        "            # If already present\n",
        "            continue\n",
        "\n",
        "        # Download\n",
        "        response = requests.get(f\"{base_url}{file}\")\n",
        "        with open(path, \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "\n",
        "    return file_paths\n",
        "\n"
      ],
      "metadata": {
        "id": "QRNk7vqCTR2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2) Load CoNLL Dataset"
      ],
      "metadata": {
        "id": "nW7wOcajQ0eC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(file_path):\n",
        "    # 1) Load and Process CoNLL Format Data\n",
        "    # 2) Return list of sentences and corresponding NER Tags\n",
        "\n",
        "    sentences = []\n",
        "    tags = []\n",
        "\n",
        "    current_sentence = []\n",
        "    current_tags = []\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "\n",
        "            # Empty indicates end of sentence\n",
        "            if line == \"\":\n",
        "                if current_sentence:\n",
        "                    sentences.append(current_sentence)\n",
        "                    tags.append(current_tags)\n",
        "                    current_sentence = []\n",
        "                    current_tags = []\n",
        "\n",
        "            else:\n",
        "                # Have to split line into components (words, POS, chunk, NER)\n",
        "                try:\n",
        "                    parts = line.split()\n",
        "                    word = parts[0]\n",
        "                    ner_tag = parts[-1]\n",
        "\n",
        "                    current_sentence.append(word)\n",
        "                    current_tags.append(ner_tag)\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "    return sentences, tags"
      ],
      "metadata": {
        "id": "8IIHgx9GQFx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3) Build Vocabulary"
      ],
      "metadata": {
        "id": "tM85VhbLR4Os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(sentences, min_freq=1):\n",
        "    # 1) Given a list of sentences, build a vocabulary\n",
        "    # Only include words that appear more than min_freq\n",
        "\n",
        "    word_freq = {}\n",
        "    for sentence in sentences:\n",
        "        for word in sentence:\n",
        "            word_freq[word] = word_freq.get(word, 0) + 1\n",
        "\n",
        "    # Text has special tokens, Need to add it to vocab to\n",
        "    vocab = {\n",
        "        \"<PAD>\": 0,      # Padding Token\n",
        "        \"<UNK>\": 1,      # Unknown Token\n",
        "    }\n",
        "\n",
        "    # Add words that appear atleast min_freq times\n",
        "    for word, freq in word_freq.items():\n",
        "        if freq >= min_freq:\n",
        "            vocab[word] = len(vocab)\n",
        "\n",
        "    return vocab"
      ],
      "metadata": {
        "id": "Rba9yYjGR3L_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4) Convert Dataset to Tensor Format"
      ],
      "metadata": {
        "id": "AvS34El7Sy92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NERDataset(Dataset):\n",
        "    # Convert Sentences and tags to Tensor format\n",
        "\n",
        "    def __init__(self, sentences, tags, word2idx, tag2idx):\n",
        "        self.sentences = sentences\n",
        "        self.tags = tags\n",
        "        self.word2idx = word2idx\n",
        "        self.tag2idx = tag2idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Convert words and tags to indices\n",
        "        sentence = [self.word2idx.get(w, self.word2idx[\"<UNK>\"]) for w in self.sentences[index]]\n",
        "        tags = [self.tag2idx[t] for t in self.tags[index]]\n",
        "\n",
        "        return torch.tensor(sentence), torch.tensor(tags), len(sentence)"
      ],
      "metadata": {
        "id": "pUySph6_SyLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, word2idx, tag2idx, path):\n",
        "    # Save model state\n",
        "    torch.save(model.state_dict(), f\"{path}_state.pt\")\n",
        "\n",
        "    # Save vocabularies\n",
        "    vocab_data = {\n",
        "        'word2idx': word2idx,\n",
        "        'tag2idx': tag2idx,\n",
        "        'idx2tag': {str(v): k for k, v in tag2idx.items()}  # Convert idx to str for JSON\n",
        "    }\n",
        "\n",
        "    with open(f\"{path}_vocab.json\", 'w') as f:\n",
        "        json.dump(vocab_data, f)"
      ],
      "metadata": {
        "id": "h7FECayJwCkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) BiLSTM Model\n"
      ],
      "metadata": {
        "id": "thFoy0C9NDxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1) BiLSTM Model Architecture\n"
      ],
      "metadata": {
        "id": "NP9_kLQyoaJn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Screenshot 2024-11-18 170258.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA8UAAACCCAYAAABvh2olAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAACBWSURBVHhe7d1/bBzVufDxxzZ1bYlXdYCodgVpbHMlNg3StRuk2E3UxlH+wBZIOASBLaLe2q0UEqjABuklLj9N30LtUiCG9iYuLchGAtlUhYT2XiVIgGKkUlIpKEYQYxSgSQWqA6TyjxDPO2f2rLO7nrXP7K53PTPfj3Qy3tk5O/Ns5pmzZ+fMbIFlExczMzPOtLi42Jl6NTY2JtXV1fqRuUzWm6+6CvGaIV5zxGuOeL0hXjPEa454zRGvN8RrhnjNEa+5MMVbqKcAAAAAAIQOnWIAAAAAQGjRKQYAAAAAhFbB9PS06zXFs7OzzrSwML1+84kTJ2TVqlX6kblM1puvugrxmiFec8Rrjni9IV4zxGuOeM0RrzfEa4Z4zRGvuTDFm16EAAAAAAAEAHef1ojXG+I1Q7zmiNcc8XpDvGaI1xzxmiNeb4jXDPGaI14znCkGAAAAAIQWnWIAAAAAQGjRKQYAAAAAhBadYgAAAABAaNEpBgAAAACEFp1iAAAAAEBo0SkGAAAAAIQWnWIAAAAAQGjRKQYAAAAAhBadYgAAAABAaNEpBgAAAACEFp1iAAAAAEBoFUxPT1v67wSzs7POtLAwvX7ziRMnZNWqVfqRuUzWm6+6CvGaIV5zxGuOeL0hXjPEa454zRGvN8RrhnjNEa+5MMWbXoQAAAAAAARAgWXTfyeYmZlxpsXFxc7Uq7GxMamurtaPzGWy3nzVVYjXDPGaI15zxOsN8ZohXnPEa454vSFeM8RrjnjNhSlezhQDAAAAAEKLTjEAAAAAILToFAMAAAAAQotOMQAAAAAgtOgUAwAAAABCi04xAAAAACC06BQDAAAAAEKLTjEAAAAAILToFAMAAAAAQotOMQAAAAAgtOgUAwAAAABCi04xAAAAACC06BQDAAAAAEKr4Pjx45b+O4FlRWcXFBQ4U68mJyeltLRUPzKXyXrzVVchXjPEa454zRGvN8RrhnjNEa854vWGeM0QrzniNRemeAvsitGaSWZmZpxpcXGxM/VqbGxMqqur9aPz/vWvf8nvf/97+fOf/yx///vf5bPPPpvbeCCfSkpKpKqqSjZs2CDXX3+9bNmyRT+Ten9eTCZ5tFR1yUEsV6lycKnao8Usx/w1QfsLvwlL+2tiKeIl97FcLUW7n27dnHaKf/GLX8j9998vU1NT8t3vflfWrVsn5eXlaX/7kA0cFBCj9sv33ntPDh48KF988YWTmA8//LDU1NQEplEmB7GcpcrB73znO87z2WyPTCy3/DVF+wu/CUP7ayrb8ZL7WM6Wot1POwftHdPV9PS0U9KlhmXHa25uVhlg3Xjjjdbf/vY3PRdYfmZnZ60nn3zSWrlypWU3GtZzzz03b382lUkeZbsuOQi/SM7BZ599Nu1cUIKQv17Q/sKvgtr+epHNeMl9+EU22/10czAnneJYUqpgAb/45JNPrIaGBmff3bt3r57rTSZ5lM265CD8KD4H//jHP+q53oX5QzW5Dz8KUvvrVbaOV+Q+/Cgb7X66Objkd59WwzaGh4fFTkrZsWOHngssf9/61rfk5ZdfdoYb3XPPPXLmzBn9jL+Qg/Cr+BzcuXOnb3MwX8h9+FVQ2t98IffhV/ls94vus+m/E5w7d86ZFhUVOVOvJiYmnOm1117rXDitEhTwm6997Wuydu1aeeyxx5zrbzZv3qyfMZNJHmWj7ueff04OwtdiOfjrX/86rRxUVHt00UUX6Ufm8p2/tL8IM7+3v5nkbybHK9p9+F2m7X66ObikZ4rVne7UBdR33nmnngP4T319vdx4442yd+9ePcc/yEEEgZ9zMF/IfQQBue8duY8gyEfuL2mnWN36XZ3+rq2t1XMAf9q2bZt8+umn8tprr+k5/kAOIij8moP5Qu4jKMh9b8h9BEWuc39JO8Xqt9DUrd8Bv1u/fr0zPXr0qDP1C3IQQeHXHMwXch9BQe57Q+4jKHKd+0vaKVY/Dq5+Cw3wu4qKCmeq9mk/IQcRFH7NwXwh9xEU5L435D6CIte5v6SdYosf50ZAqAv9Fb/t0+QggsKvOZgvvE8ICnLfG94nBEWuc39JO8UAAAAAACxndIoBAAAAAKFVODMzI25ldnbWKW7PmRSGbyCI1G+fue3vqUomeZSNukDQeM1BVVR75DZ/sZKNHHR7brGSSV1VaH8RRH5rf92eMymZHq+AoMlV7nOmGAAAAAAQWoXFxcXiVgoLC53i9pxJiV0cDQRJUVGR6/6eqmSSR9moCwSN1xxURbVHbvMXK9nIQbfnFiuZ1FWF9hdB5Lf21+05k5Lp8QoImlzlPtkDAAAAAAgtOsUAAAAAgNCiUwwAAAAACC06xQAAAACA0KJTDAAAAAAILTrFAAAAAIDQolMMAAAAAAitYHWKX2p1ft+t9SX9OJ8+G5Hexk45oB8u6PSo9N+xWdasKHC2X5XSilppfWJETn+ll0Gozc7OyuTkpH4UdAekVedB6rJGeo/rxTORq2OGsx6DbU5ebjkd05AX4cr99BzY7naMsEtphdRu75OR03pBx7j0Xmk/d2Wv/VdUtH5rVtvr8V+uOb8dC5Xt0bWej6FJBs84s1zobY+rh+Ai9zM0NS4HftkqtRWlc/mmcrXpnmEZn9LLpMPL5/t05WIdmIczxUtk/Ok26XzlpH60gNN2B6ByjbQ/ekhOXt4obT9us0ujRKaOyOBt9bJiY6+M0jEOPfUj5O3t7fLYY4/J9PS0nhtwqxt0PriVVolcqJcDAiyUuZ+WSmlIOk40rp2SI8/ukvrKXTKSjXbUQ3tdurY1YVvatlQ68yu3xM1TZWOFM/+8AzLwUopP7MeHpf8d/TcCj9zPwLv9srmiSpruGpSpqzpkz/NDMvT8Hum4SuTQg1ul6v/US+876fWMjT/fZyAX64ALKwU7AZ2SruPHj1vq5e+99149Jwf+1OKss+VP+nEeffBIxN6WFmu/fpzKsZ9V2suV2ds8oefETFrHHlCvIVbz4KSeh3xKZ3/OJI+S677xxhvONnzzm9+0nnjiiQVfN1Y35zmYFfutFnu75ebFsicLcnXMcNYTsXre149TMV0upNLdn1V7lI7kHPQim3W95L6Sl/Y3j/bfbB8vUrS3x34ebUfbDugZLhaqHy+j9nqRY010GyJWZK09vWbAfsX5nM8Vqystu3udm+PjMpLO/pzNHPQik7pK/PEqPO1+Fn2532ors3OkrNna975LJn00YDWr56XRGkhOZQOmn+8zkYt1+EUucz/gZ4r1UKPtw3LqxXapjQ13Kq2Srb8ckfMjqpKWK9XDLP5jq/S+ET/uKrZc8oCGxPlqGFTVXaP2X4PStMgwp/EP1QCuRmm9piw6Y06JRG7vsp+xX2/kcHSWNnV8WNqvWjE3HGTFVa3S92bC+DDHqRc7ZfNl0WUKVtRK56uno0O05rbHLJ6Yxdeb9D6mfL+jTr/ZJ62LxGEaaxh873vfk02bNsk///lPufXWW2X16tXy1FNPyczMjF4ipGJDjt8ckd7mCr2vlErtT+z98Ct7P3ul8/y+eJmd0277jxqqFKv7tRVO3XnDq746LSO/3CpV+vig9uvNd0TXkeC0eq0qKY1txx2H5u37DpPlkodPJ8Qaq6vyol2GP9bLxNiv37e9dm6ZiuZeGXmzV9bEvx58gdxPX2RtjTOdnMtn3U7FDZ82lU577U2NtG2P2Hk+IMPzhlCPSv+ToxK5ZafU6TkIPnLfu9FHdkn/6TLZ+dKQtF1eoufGubRFhl7aKWVyQHbeM6Jnmn0edv98n/TZN4d9CGRXOIZPv9QmkRsOS+TuARl6pkdaVo/L8F310vZc0qdetVzzfqm4M7pcowxL58ZKaX/F2xCL2tuGZM9N5fZfddKhhmzcVht9wkXtVap5OyD9T4/LvLVc2CL7LUsmH2/QM+xO4ivtUmknWv+ZRul5xn5ttZ1nBmVXXaX9Qfd88p1+bqvzIfjQhW3OsJE9/1Ui/Q21sut1vYBHput1GLzfp+0P95V1u2Tw44h0PGm/3pMdEvlYvV7D3PWUntYZEt3d3fovkVOnTsktt9wiVVVV8tvf/lbOnj2rnwmjcem+ul56Pm219/cB6dlWIUf2bpWGxs1See0Bqf15dB+rO2PndF3bvGv2Bn9UL52jTdFcuTUi43bdqo3xH5rHpW/jCqm/67CU79gjQ2q5HeVy7FE7z+riLnH4akR2Vdqv9eKkNPxM7f/dEnmlSRoeOKIX0EyXcxWLtVl61HbcXiclb/XL1o1d9sdm7atR6d1SL7uePSk1t9vba+dOw2in1F/dHRcT/ITc927q1CF56NFhkbI2ad2iZ2bAa3udjshNqtPrMoT6nQEZ/DAibdfZnWaECrnvxREZ2Gu3cuU7pW2DnuVmQ4d0rbU/i+4dkFi32MSCn+/z0IdAlsVOMSeXyclJp7g9Z1Lef//93A/hmDc86QOrRw1FkojVPapnKWeTh2fGlksaFnX2bWv3anv+6t3WMWeGXm7esKX5842HPpw9Zu3bUuZst1xQZtVc02H1PLPfevsjt8FTx6Lbc80+a+KsnuWYsAauid/Ow9bOEvvx2m7rWNxyE8MtVolb3IvGY7re2Pu42PutX8+u93b8600MWI0XlFiRB962H5iuM3fU/1FXV5fr/p6qZJJHqepu2rTJKioqiu4zdiksLHSml112mfXUU09Z//73v+fqqvn+G0al95eFytoee2/TdN6X3DRk7x0xdu6Wq2UT98XJwUZn2bmhlLquGq4YP4pqQi8XO5ZMDjbbjyutjpGkvPzrbmcoY2zI5MnH6+zlko8jx6xunRexYdGmy807prnGGjveLP76PevU6+dguPgSUdvuNQdVUe2R2/zFSqocNClLUdck99VyeWl/8yg69DhFuaTZGvhIL+jQ7VTcMcR0+LS39jrJvM8nic5vw0lrz3r776Qh1M7QbWebc3h5yTKi3rvl0P6alEzqquJ2vAp+u58lZ4eM8yOaczVWz7h6ZPp5ONbexh8vYp9989CHCIFc5n44zhRf0SrNV+i/lQsiUrvWnh4ZTTxrsrZLuuOHRV1QI223REQ+PCAHPtTzss3elrb/OSkn/7pPdl9dKSf/t1c6tzdJ7WWlUlBaK+0vxH0j/e6wDNvbESkXOfSi/fcLsXJIJi60Z344LAfUWda39suQXanhtjaJXBCtqpRd1ykd6ssnr0zXG7PY+63fz8gtbVITt31S1iL7z07KsZ/VeF9niDzwwANy7tw5/Sh6h0rlk08+kR07dsiaNWvkmWeeka++ysadZfJooRtt3RCRUr1YTPO2ZjmfvWWy4hJ7krQvltTUizrPMpnw1pTIzttb4uratbe1id2wyuCLejjTS8POfrziowNx+6JdxqdEpdTwK4fsf6fk0P+OON9QdyYcRyLScbcaWBljulxqibHa3fUr1BDRUXnbOVV8Sva/mOr1VVTwK5Pc/8Mf/pCwTHi43Ghrnb3/fzYsrVdulv539WKZsHPIuL1OW7lsbalLGkI9KgPPjkvdT1rtKBFGoWn3M/XhuJiMt1IiV6pPA3bGZusty0cfAtmlO+LzxHrN6VoeN9rS377En1VyJM9P9e2NLeE1c/Mtz+TEB9bbz/dYLVfYr2mvu+YRfU5Ub8tCxTkDtsA30kM32cvNbadhPKbrjdVb7P0+0ObUWfBslfE6c8dtG/JZYt8UJ5eCggJnWl1d7Ux9e6Z43n6Zguv+nmJffL/Hspuo88s6dd1ubKXrb9pnnYz9rbYpVVmn1qOXc7tJzus7rZK59ZguZ0uOzTVWW8L8Y1a3OnbcNOQ8lSA5fp+Ze79DXhbL/W9/+9vONFxnit3b28mj3c4+L1tULivzjw3GZ4pdpGyvk6XKXS1hGz7aY9ndYqsxdtOuv+62yqXO2uOc8Q7vmWJKkNv9LPlywGpU74lBfuz/L/XeZfFMsds6E/I+k3WEVzr7c7p92AL1j73CeWIX8RcXFztTr8bGxuTyyy8XOxC577779Nwlpm5Cc+2g2DufDFyjZqiL16ukU3rkg6Mdcd+wJs/Xj2v2i/VM0pka/Zp2B0z2XZ1qufnz1W8UVt1VI/utAefmG2n5yn7djfbrvtlmv84+aZwXXwoLLKcu4G+S2HYaxmO63nnva0zSfJPXM15n7qgbJ3z/+9+XH/zgB3rO4mLf7BYVFTlTL1LVVbn56KOPytTU/HMSdoPpfIN80UUXye7du6WjoyO3OZgV6neKm2Tw5uT9MgXXfSXFvni8V9b8R6fUxJZ16h6RnvePScfl0UWidP3KAZn8U530ue7XyeLrtEjC7T3e6pKKq4al01mP6XL24+TYUuVFwvwj0lVRKw9tGhJrsFkvoCXH7zPp5KAyMTEhK1as0I/Mec1ftX2xJjWd3I/VzyT3L774YufMkboO0X+5nx6nXXtWXdPr1t6ekv6GCml/Nfb8/GPDwvUNJbfXevacVLmrJW7DKemrq5BdK6PHiNG7K6T21S45ObJTyr0eHwNiubS/qWQr9xW341Xw2/1s0e2f7Ja3T3ZL9DZ7bvRx4PhOOTy5R+pij9P6fJ+qrk3nfV76EAGhcsPr/px2H9ZOQlehPFPsnBVKFP22psHa5zyRarn9Vpu9Xs/f8oxHvw0u/7/qGlp3B3fYrxt7Hefb4oWXd4xGvxlv+O/kaPQZpLntNIzHdL3z3teYpPnjPZZ9oLIijyQu5Sy3TqyymwasCeN15k46+3MmeZSqrv1hd+5b4ViJfXu8cuVKq6enx/r888+duulsc/7l+kxxibXzdf04Rl+XVHLrYfvBZPQ6dvXzDV9Gn3anlyvfbSXvtdFrmWNngE2XsyXH5hqrLWH+SWvfJvfXT1nfJ9S2p7M/+/0nmWJMcl9dR8VPMsXT+TD3/Pxjg9GZYq/tdbJFci95G6L3BWi2jznR+yPUPR5rpcN7png5tL8mMqmruB2vgt/uZ0/0p9NK7Fxb4Fp/fT+Qkh0H9Qx9XEjr832qurFll6gPERLp7M/p5mA4rik29Wpv4nVHU4ek9+ejIuubpUldOCilUrbSnowckWNx1yCcfnFABvTfnqxukIbVIqf+X5t0Jdy2Xfu4X3qftqfr68W599y6VmlTyz/aI8MJi5+W4RZ1TdNWGVTzr2iWZnu5Q4/3n78rrvJGn/QkXFdlGI/pek2tbpRG+/VGn+yXI/Hb9+6g9L8lUlFTJ2XZXmdAnDlzRh5++OG5b5TVN8SKOjvU29srJ06ccL4lLilx+RkCpDAl/U8OJ/wc0uij3TIoJdJ2nbrbbIk036TOuB6Q7ifm7u8c9e5Dzk8cVT2ormIqkYbrGuydtld6Xox7ta9Gpe9X8T+pYLpcusqlSW33KTvfE+7SfloG9w7qv+E35H6a3rXb0Vft6aaGaDuaLq/tdYbKr2uVOhmWobv7pf9Ug7Rtcz6EIITIfW8id+2RtrIpGdzeJH3vuFzl//GgbN3ykIxLo/T/PHa3+Cx8vs91HwJZR6c4wah0XblGWn85KMPPdklT5WbpO10jPU+rIUuK/WHzJjuBpvpk68ZO6XthWPruqJfIDaMSUTeSilNaVmH/Oyy9d9uv9dap6Mx5ItL9So/UyBF5aOMK57eEm37SLu12aVK/zXtZuxyYil9/RDofb5GyKTuhV66R9qeG7e3slfaNEdn63JTUPNAtLc41/hHperJNyt7pkjWRrdL77LAMqt9X3diX8MHfPB7T9ZrSr/fhQ1Krt2/4qXZZc2WXjJa1Sc8ONaAt2+sMhscee0y+/PJL/Uic4VK/+tWvnEbxjjvuCFaj+Lr9/63zwa089EqqvPKqREpe2SoRJwcGpXf7Gllz1xEpu3lIujfpJbZ1S886+whx9xqpaOySQZUr9zTpfbZF9twaHaRVfvMeezm7MW6OSP0dfTL8Qp+028eUzrecp+eYLpeu8h19svsKuxN8bdzrR1bw+8Q+FqrcT8uI9CYdI1obqqQ0on6qrEx2PtCm29FU5tePlf6/q+e9ttcZunSrtK63P0U80SenNrXoD9UII3LfowsbZd/IPmmQQ7LrylJZc22X8/lWtYNd19ZK6WWtMnymTnqODsV9jszG5/tc9yGQdep0sZtsDP9QL5/TIRzzhielGEI5b37scbc19N/NVqX6OSP7dcrWtVlD7ycPv5iwDj9yfpmSy5utnpGJ6NCn+OFMEwetjv8scZaJ3oRnAZ8etvb8uMGKlOvlVSkpt2pu3mMd/lQvE2diZI/Vsk7/LITahvIaq+35D+bdtGdipMdqvly/Zom9zPDB6E++JAy7MozHtvh6Td/vqMTXK7Eqr+uxDsf/zozNNNZcUOvP5/Atu1G0vvGNbzjbcfHFF1t2o+gMlXQTq5vONuefHh64SJkbfu86LDHFvpjqRlsjdr7G9rMLyq2Gn+1P+ikw29mT1tDtDXO5on6SJaL22eQcnfzAGvpxjVV2QXQ55zjyuF5P/A29TJZLji3VEEy3+ROHrZ7rKqM/w2aXcrWtv0tR3yfUtqezP/t9+LSX3FfCOXzapagc3dSR1I7PPzakrK9LQr54bK/npMpdLXn4tBIdQi1Jl0IxfNpUNnPQi0zqKvHHq/C0+0vAbmP3P9Ji1cTlqvoM2fLIfusD17cw3c/3ee5DBJx6D3KV+8HqFKctVWcuaHScIWtMsyWXiakk133wwQetSy65ZNEPxEqsrn9yEDkxrD6YJ/2OuI+kuz/7vVPsJfeVsHWKEXz5bn+9yKSuEn+8ot33g7D0IfIjl7nP8GnAB9SdJS+99FL56KOP5Pbbb2e4FBY0ctsKKa3YJQfir9lX1+O/MGxPa6Qm4U7bWM7IfSCcyH0gt+gUAz6gbqzxwx/+kEYRRupuaJWSU33SdGVr9Jr9F/qkM3Y9/iNd0niBXhDLHrkPhBO5D+QWnWIACJoNe2T89R5plgPSuX2rbL1hl/SdWiMdz38gh++M6IUAAACg0Cl2VErHUUss/UP+waXjTP5xcQCBU7ahQ4ZGJ5yf8VBl8v2D0rOtUjjnAABAtoSlDxF8dIoBAAAAAKFFpxgAAAAAEFqFMzMz4lbUXe9UcXvOpKjhekDQnDt3znV/T1UyyaNs1AWCxmsOqqLaI7f5i5Vs5KDbc4uVTOqqQvuLIPJb++v2nEnJ9HgFBE2ucp8zxQAAAACA0CosLi4Wt6JuBa+K23MmpaCgQK8CCI6ioiLX/T1VySSPslEXCBqvOaiKao/c5i9WspGDbs8tVjKpqwrtL4LIb+2v23MmJdPjFRA0ucp9sgcAAAAAEFp0igEAAAAAoUWnGAAAAAAQWnSKAQAAAAChRacY8IAb2AD5RQ4C4UTuA+GUq9ynUwwAAAAACK0l7RSXlJTI1NSUfgT41+TkpDP9+te/7kz9ghxEUPg1B/OF3EdQkPvekPsIilzn/pJ2iquqquS9997TjwD/Gh0ddaarV692pn5BDiIo/JqD+ULuIyjIfW/IfQRFrnN/STvFGzZskIMHD4plWXoO4E9/+ctfnGl9fb0z9QtyEEHh1xzMF3IfQUHue0PuIyhynftL2im+/vrr5YsvvpDf/OY3eg7gT/39/bJlyxZZtWqVnuMP5CCC4ne/+50vczBfyH0EhV/b33wh9xEUuW73l7RTrAJR5d5775V//OMfei7gL/fdd5+MjY3JT3/6Uz3HP8hBBIHKwePHj/syB/OF3EcQ+Ln9zRdyH0GQj3Z/STvFysMPPyyfffaZ3HzzzXMXTAN+8fTTT8v9998vN954ozQ1Nem5/kIOws9iOdje3u7bHMwXch9+FoT2N1/IffhZvtr9Je8U19TUyODgoBw6dEg2btwohw8f1s8Ay5v6lupHP/qRk5Dd3d16rv+Qg/CrWA5effXV0tfXp+fCFLkPvwpK+5sv5D78Kp/tfsHx48ddr8SPXaCf7g8mq2+mSktL9SORV199Ve655x45efKk863ftm3bZP369VJRUcEPsmNZUPusutOdurBfXcOkhmypfVU1yMn7s6lM8ijbdclBLHepcvDBBx90nk93Pw1C/npB+wu/CXr760U24yX3sdylyv1M2v20c9Cu6Gp6etop6VKd7WRffvmldffdd1srV65UW0uhLNuyZcsW6+WXX9Z7rvv+bCKTPFqKuuQgxS8lPgczyQUlKPlrivaX4ucS1PbXVLbjJfcpfinZavfTrVug/rE3ZJ6ZmRlnWlxc7Ey9Uj396upq/Wi+1157TY4ePepc8xC/CefOnXOmRUVFztSLfNVVJiYmZMWKFfqROeI1t9R11Q/eq99CU7d+T77T3WL7cyqZ5NFS102Vgwr7sxniNWdSN1UOLnV7lMpyzt+F0P6aIV5zS103bO3vQpYy3uWW+wr5ayao8S5Fu59u3bx1ilPJx5ugEK83xGuGeM0Rrzni9YZ4zRCvOeI1R7zeEK8Z4jVHvGaW/EZbAAAAAAAsV3SKAQAAAAChRacYAAAAABBadIoBAAAAAKFFpxgAAAAAEFp0igEAAAAAoUWnGAAAAAAQWnSKAQAAAAChRacYAAAAABBadIoBAAAAAKFVMD09bem/E8zOzjrTwsL0+s0nTpyQVatW6UfmMllvvuoqxGuGeM0Rrzni9YZ4zRCvOeI1R7zeEK8Z4jVHvObCFG96EQIAAAAAEAAFlk3/nWBmZsaZFhcXO1OvxsbGpLq6Wj8yl8l681VXIV4zxGuOeM0RrzfEa4Z4zRGvOeL1hnjNEK854jUXpng5UwwAAAAACC06xQAAAACA0KJTDAAAAAAILTrFAAAAAIDQolMMAAAAAAgtOsUAAAAAgNCiUwwAAAAACC06xQAAAACA0KJTDAAAAAAILTrFAAAAAIDQolMMAAAAAAgtOsUAAAAAgNAqmJ6etvTfCWZnZ51pYWF6/eYTJ07IqlWr9CNzmaw3X3UV4jVDvOaI1xzxekO8ZojXHPGaI15viNcM8ZojXnNhije9CAEAAAAACIACy6b/TjAzM+NMi4uLnalXY2NjUl1drR+Zy2S9+aqrEK8Z4jVHvOaI1xviNUO85ojXHPF6Q7xmiNcc8ZoLU7ycKQYAAAAAhBadYgAAAABAaNEpBgAAAACElMj/B7PN6qCwolubAAAAAElFTkSuQmCC)"
      ],
      "metadata": {
        "id": "qP8MmLBZoczo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWFYjM_dMH_p",
        "outputId": "e55a8e53-4293-4b39-b6c3-13ba1438e53e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-04 01:02:30--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2024-12-04 01:02:30--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-12-04 01:02:30--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n",
            "\n",
            "2024-12-04 01:05:09 (5.18 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Integrate Pre-trained Word Embeddings\n",
        "\n",
        "Why?\n",
        "\n",
        "Pre-trained embeddings like GloVe or FastText provide rich semantic context and are highly beneficial for tasks like NER."
      ],
      "metadata": {
        "id": "iB1QSz2uN9jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create an Embedding Matrix:\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def load_glove_embeddings(glove_path: str, embedding_dim: int):\n",
        "    \"\"\"\n",
        "    Load GloVe embeddings into a dictionary.\n",
        "    \"\"\"\n",
        "    embeddings = {}\n",
        "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings[word] = vector\n",
        "    return embeddings\n",
        "\n",
        "def create_embedding_matrix(word2idx: dict, glove_embeddings: dict, embedding_dim: int):\n",
        "    \"\"\"\n",
        "    Create an embedding matrix for the vocabulary.\n",
        "    \"\"\"\n",
        "    vocab_size = len(word2idx)\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "    for word, idx in word2idx.items():\n",
        "        if word in glove_embeddings:\n",
        "            embedding_matrix[idx] = glove_embeddings[word]\n",
        "        else:\n",
        "            # Initialize with random values for missing words\n",
        "            embedding_matrix[idx] = np.random.uniform(-0.1, 0.1, embedding_dim)\n",
        "\n",
        "    return torch.tensor(embedding_matrix, dtype=torch.float32)\n",
        "def create_glove_embedding_matrix(ner_dataset, glove_path=\"glove.6B.100d.txt\", embedding_dim=100):\n",
        "    \"\"\"\n",
        "    Creates and returns a GloVe embedding matrix.\n",
        "\n",
        "    Args:\n",
        "        ner_dataset: The NERDataset instance containing the word2idx mapping.\n",
        "        glove_path: Path to the GloVe embeddings file.\n",
        "        embedding_dim: Dimension of the GloVe embeddings.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The GloVe embedding matrix.\n",
        "    \"\"\"\n",
        "    glove_embeddings = load_glove_embeddings(glove_path, embedding_dim)\n",
        "    word2idx = ner_dataset.word2idx\n",
        "    embedding_matrix = create_embedding_matrix(word2idx, glove_embeddings, embedding_dim)\n",
        "    return embedding_matrix\n"
      ],
      "metadata": {
        "id": "MG3GoX03LyIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchcrf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torchcrf import CRF\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_tags, num_layers=1, dropout=0.5):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "\n",
        "        # Word Embedding\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(\n",
        "            embedding_dim, hidden_dim // 2, num_layers=num_layers,\n",
        "            bidirectional=True, batch_first=True, dropout=dropout if num_layers > 1 else 0\n",
        "        )\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, num_tags)\n",
        "        self.crf = CRF(num_tags, batch_first=True)\n",
        "\n",
        "    def forward(self, sentences, lengths, tags=None):\n",
        "        embedded = self.embedding(sentences)\n",
        "        packed = pack_padded_sequence(embedded, lengths, batch_first=True)\n",
        "        lstm_out, _ = self.lstm(packed)\n",
        "        lstm_out, _ = pad_packed_sequence(lstm_out, batch_first=True)\n",
        "        emissions = self.hidden2tag(lstm_out)\n",
        "\n",
        "        if tags is not None:  # During training\n",
        "            loss = -self.crf(emissions, tags, mask=(sentences != word2idx[\"<PAD>\"]), reduction='mean')\n",
        "            return loss\n",
        "        else:  # During inference\n",
        "            return self.crf.decode(emissions, mask=(sentences != word2idx[\"<PAD>\"]))\n",
        "\n",
        "\"\"\"\n",
        "class BiLSTM(nn.Module):\n",
        "    # 1) Bi directional Long Short Term Memory\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_tags, num_layers=1, dropout=0.5):\n",
        "        super(BiLSTM, self).__init__()\n",
        "\n",
        "        # Word Embbeddings for Text\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim//2, num_layers=num_layers,\n",
        "                            bidirectional = True, batch_first=True,\n",
        "                            dropout = dropout if num_layers>1 else 0)\n",
        "\n",
        "        # Linear Layer to map LSTM output to tag spaces\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, num_tags)\n",
        "\n",
        "        # Dropout for regularization\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, sentences, lengths):\n",
        "\n",
        "        # Get embeddings\n",
        "        embedded = self.dropout(self.embedding(sentences))\n",
        "\n",
        "        # Pack padded sequences for LSTM\n",
        "        packed = pack_padded_sequence(embedded, lengths, batch_first=True)\n",
        "\n",
        "        # Apply LSTM\n",
        "        lstm_out, _ = self.lstm(packed)\n",
        "\n",
        "        # Unpack sequences\n",
        "        lstm_out, _ = pad_packed_sequence(lstm_out, batch_first=True)\n",
        "\n",
        "        # Project to tag space\n",
        "        tag_space = self.hidden2tag(lstm_out)\n",
        "\n",
        "        return tag_space\n",
        "        \"\"\"\n"
      ],
      "metadata": {
        "id": "lNiW2VwDTu2T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "a40a2954-bc43-4292-c8b0-9c37f1220582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchcrf in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchcrf) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from torchcrf) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->torchcrf) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->torchcrf) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->torchcrf) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->torchcrf) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->torchcrf) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->torchcrf) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->torchcrf) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->torchcrf) (3.0.2)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchcrf'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-02627244f1b0>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchcrf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCRF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchcrf'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2) BiLSTM Model Training Infrastructure\n"
      ],
      "metadata": {
        "id": "aY3e1QoZmKYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    # Collate function for DataLoader\n",
        "    # Pad sequence length in batch to same length\n",
        "\n",
        "    # Sort the batch in descending order\n",
        "    batch = sorted(batch, key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    # Unzip the sorted batch\n",
        "    sentences, tags, lengths = zip(*batch)\n",
        "\n",
        "    # Pad sequences in batch\n",
        "    sentences_padded = pad_sequence(sentences, batch_first=True)\n",
        "    tags_padded = pad_sequence(tags, batch_first=True)\n",
        "\n",
        "    return sentences_padded, tags_padded, lengths"
      ],
      "metadata": {
        "id": "5J9Fwf__QV1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, optimizer, criterion, device):\n",
        "    # Trains model for one epoch\n",
        "    # Returns average loss\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_sentences, batch_tags, lengths in tqdm(train_loader):\n",
        "        # move batch to device\n",
        "        batch_sentences = batch_sentences.to(device)\n",
        "        batch_tags = batch_tags.to(device)\n",
        "\n",
        "        # Clear Gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward Pass\n",
        "        tag_scores = model(batch_sentences, lengths)\n",
        "\n",
        "        # # Reshape for loss calculation\n",
        "        # flattened_scores = tag_scores.view(-1, tag_scores.shape[-1])\n",
        "        # flattened_tags = batch_tags.view(-1)\n",
        "\n",
        "        # # Calculate Loss\n",
        "        # loss = criterion(flattened_scores, flattened_tags)\n",
        "\n",
        "        # Calculate Loss on Actual Seq Length\n",
        "        loss = 0\n",
        "        for i in range(len(lengths)):\n",
        "            seq_len = lengths[i]\n",
        "            loss += criterion(tag_scores[i, :seq_len], batch_tags[i, :seq_len])\n",
        "        loss = loss / len(lengths)\n",
        "\n",
        "        # Backward Pass and Optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(train_loader)"
      ],
      "metadata": {
        "id": "_Ao9jmNwQawZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    # Download and Load Data\n",
        "    train_path, val_path, test_path = download_conll2003()\n",
        "    train_sentences, train_tags = load_dataset(train_path)\n",
        "    val_sentences, val_tags = load_dataset(val_path)\n",
        "\n",
        "    # Build Vocabularies\n",
        "    word2idx = build_vocab(train_sentences)\n",
        "    tag2idx = {tag: idx for idx, tag in enumerate(sorted(set(tag for tags in train_tags for tag in tags)))}\n",
        "\n",
        "\n",
        "    # Create Dataset\n",
        "    train_dataset = NERDataset(train_sentences, train_tags, word2idx, tag2idx)\n",
        "    val_dataset = NERDataset(val_sentences, val_tags, word2idx, tag2idx)\n",
        "\n",
        "    # Create Dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "    val_loader= DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    # Model\n",
        "    model = BiLSTM(\n",
        "        vocab_size = len(word2idx),\n",
        "        embedding_dim = 100,\n",
        "        hidden_dim = 256,\n",
        "        num_tags = len(tag2idx),\n",
        "        num_layers = 5,\n",
        "        dropout = 0.5\n",
        "    )\n",
        "\n",
        "    # Setup Training\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=word2idx[\"<PAD>\"])\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "    # Training Loop\n",
        "    num_epochs = 10\n",
        "    for epoch in range(num_epochs):\n",
        "        loss = train_model(model, train_loader, optimizer, criterion, device)\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss:.4f}\")\n",
        "\n",
        "    save_model(model, word2idx, tag2idx, \"bilstm_ner_model\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6Ui11O-khiG",
        "outputId": "b6a39815-4a3c-44b1-ceb0-214c7ec12da9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:17<00:00, 27.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.7492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:13<00:00, 33.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 0.5415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:13<00:00, 33.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 0.4244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:14<00:00, 32.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 0.3607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:14<00:00, 33.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 0.3213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:13<00:00, 33.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 0.2882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:13<00:00, 33.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 0.2664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:13<00:00, 33.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 0.2446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:13<00:00, 33.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 0.2311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:14<00:00, 32.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 0.2161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3) Benchmarking Functions"
      ],
      "metadata": {
        "id": "H3Q6tcO4scEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "import numpy as np\n",
        "from typing import List, Tuple, Dict"
      ],
      "metadata": {
        "id": "RWLLNWxFsbvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def benchmark_model(model, dataloader, word2idx, tag2idx, idx2tag, device):\n",
        "    \"\"\"\n",
        "    Benchmark the NER model and return comprehensive metrics\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "    # Collect true and predicted labels\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "    print_model_output = True\n",
        "    with torch.no_grad():\n",
        "        for batch_sentences, batch_tags, lengths in dataloader:\n",
        "            batch_sentences = batch_sentences.to(device)\n",
        "            batch_tags = batch_tags.to(device)\n",
        "\n",
        "            # Get predictions\n",
        "            # logging.debug(type(batch_sentences))\n",
        "            model_output = model(batch_sentences, lengths)\n",
        "            if print_model_output:\n",
        "                print(model_output)\n",
        "                print_model_output = False\n",
        "\n",
        "            # If model returns a list, extract the tag scores\n",
        "            if isinstance(model_output, list):\n",
        "                # Try different common list indexing patterns\n",
        "                if len(model_output) == 2:\n",
        "                    # Common pattern: [loss, tag_scores] or [hidden_states, tag_scores]\n",
        "                    tag_scores = model_output[1]\n",
        "                elif len(model_output) > 2:\n",
        "                    # If more than 2 elements, try the first two\n",
        "                    tag_scores = model_output[0]  # or model_output[1]\n",
        "                else:\n",
        "                    # Fallback to first element if only one other element exists\n",
        "                    tag_scores = model_output[0]\n",
        "            else:\n",
        "                logging.debug(f\"model_output is a {type(model_output)}\")\n",
        "                tag_scores = model_output\n",
        "\n",
        "            # Ensure tag_scores is a tensor\n",
        "            if not isinstance(tag_scores, torch.Tensor):\n",
        "                print(tag_scores)\n",
        "                # Add debug print to understand the structure\n",
        "                print(\"Model output:\", model_output)\n",
        "                print(\"Tag scores:\", tag_scores)\n",
        "                raise TypeError(f\"Expected tag_scores to be a tensor, but got {type(tag_scores)}\")\n",
        "\n",
        "            logging.debug(len(tag_scores))\n",
        "            predictions = torch.argmax(tag_scores, dim=2)\n",
        "\n",
        "            # Process batch\n",
        "            for i in range(len(lengths)):\n",
        "                seq_len = lengths[i]\n",
        "                true_labels.extend(batch_tags[i, :seq_len].cpu().numpy())\n",
        "                pred_labels.extend(predictions[i, :seq_len].cpu().numpy())\n",
        "\n",
        "    # Dynamically get unique labels from true and predicted labels\n",
        "    unique_labels = sorted(list(set(true_labels) | set(pred_labels)))\n",
        "    unique_target_names = [idx2tag[label] for label in unique_labels]\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(\n",
        "        true_labels,\n",
        "        pred_labels,\n",
        "        labels=unique_labels,\n",
        "        target_names=unique_target_names,\n",
        "        zero_division=0\n",
        "    )\n",
        "\n",
        "    return true_labels, pred_labels, report"
      ],
      "metadata": {
        "id": "mq0H_W0Wso6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_confusion_matrix(true_labels, pred_labels, idx2tag):\n",
        "    \"\"\"\n",
        "    Create and save a confusion matrix visualization\n",
        "    \"\"\"\n",
        "    # Get unique labels\n",
        "    unique_labels = sorted(list(set(true_labels) | set(pred_labels)))\n",
        "\n",
        "    # Create confusion matrix\n",
        "    cm = confusion_matrix(true_labels, pred_labels, labels=unique_labels)\n",
        "\n",
        "    # Get tag names for unique labels\n",
        "    tag_names = [idx2tag[label] for label in unique_labels]\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=tag_names,\n",
        "                yticklabels=tag_names)\n",
        "    plt.title('Confusion Matrix for NER Model')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('ner_confusion_matrix.png')\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "djU93T6cspmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detailed_error_analysis(true_labels, pred_labels, idx2tag):\n",
        "    \"\"\"\n",
        "    Perform detailed error analysis\n",
        "    \"\"\"\n",
        "    # Identify misclassified instances\n",
        "    misclassified = []\n",
        "    for true, pred in zip(true_labels, pred_labels):\n",
        "        if true != pred:\n",
        "            misclassified.append({\n",
        "                'true_label': idx2tag[true],\n",
        "                'pred_label': idx2tag[pred]\n",
        "            })\n",
        "\n",
        "    # Aggregate misclassification stats\n",
        "    error_counts = {}\n",
        "    for error in misclassified:\n",
        "        key = f\"{error['true_label']} -> {error['pred_label']}\"\n",
        "        error_counts[key] = error_counts.get(key, 0) + 1\n",
        "\n",
        "    # Sort errors by frequency\n",
        "    sorted_errors = sorted(error_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Print top errors\n",
        "    print(\"\\nTop Misclassification Patterns:\")\n",
        "    for error, count in sorted_errors[:10]:\n",
        "        print(f\"{error}: {count} times\")\n",
        "\n",
        "    return misclassified, sorted_errors"
      ],
      "metadata": {
        "id": "OJw7qI8dspfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4) Loading the Model"
      ],
      "metadata": {
        "id": "pwOd8FBDs4mR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model_and_vocab(path):\n",
        "    \"\"\"\n",
        "    Load the saved model and vocabularies\n",
        "    \"\"\"\n",
        "    # Load vocabularies\n",
        "    with open(f\"{path}_vocab.json\", 'r') as f:\n",
        "        vocab_data = json.load(f)\n",
        "\n",
        "    word2idx = vocab_data['word2idx']\n",
        "    tag2idx = vocab_data['tag2idx']\n",
        "    idx2tag = {int(k): v for k, v in vocab_data['idx2tag'].items()}  # Convert back to int\n",
        "\n",
        "    # Initialize model with same parameters\n",
        "    model = BiLSTM(\n",
        "        vocab_size=len(word2idx),\n",
        "        embedding_dim=100,\n",
        "        hidden_dim=256,\n",
        "        num_tags=len(tag2idx),\n",
        "        num_layers=1,\n",
        "        dropout=0.5\n",
        "    )\n",
        "\n",
        "    model.load_state_dict(torch.load(f\"{path}_state.pt\", map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")))\n",
        "    return model, word2idx, tag2idx, idx2tag"
      ],
      "metadata": {
        "id": "YANmIDK0vp1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5) Benchmarking and Results"
      ],
      "metadata": {
        "id": "nULWf5hPtBUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Load model and data\n",
        "    model, word2idx, tag2idx, idx2tag = load_model_and_vocab(path= \"bilstm_ner_model\")\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Load test data\n",
        "    _, test_path, _ = download_conll2003()\n",
        "    test_sentences, test_tags = load_dataset(test_path)\n",
        "\n",
        "    # Create test dataset\n",
        "    test_dataset = NERDataset(test_sentences, test_tags, word2idx, tag2idx)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    # Benchmark model\n",
        "    true_labels, pred_labels, report = benchmark_model(\n",
        "        model, test_loader, word2idx, tag2idx, idx2tag, device\n",
        "    )\n",
        "\n",
        "    # Print classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(report)\n",
        "\n",
        "    # Visualize confusion matrix\n",
        "    visualize_confusion_matrix(true_labels, pred_labels, idx2tag)\n",
        "\n",
        "    # Perform error analysis\n",
        "    misclassified, sorted_errors = detailed_error_analysis(\n",
        "        true_labels, pred_labels, idx2tag\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w10Be1XTm19r",
        "outputId": "c6cdcdc3-7577-4f7d-e2c8-4834b7af398f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-99dbc8d6d6bc>:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(f\"{path}_state.pt\", map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-7.6655e+00, -5.1509e+00, -7.1686e+00,  ..., -1.9231e+00,\n",
            "          -2.0922e+00,  7.2411e+00],\n",
            "         [-8.5205e+00, -5.0456e+00, -7.4655e+00,  ..., -1.0728e+00,\n",
            "          -1.1730e+00,  3.9588e+00],\n",
            "         [-9.8689e+00, -4.6285e+00, -8.4453e+00,  ...,  2.5446e-01,\n",
            "          -1.7670e+00, -1.1796e-01],\n",
            "         ...,\n",
            "         [-8.2645e+00, -3.7462e+00, -6.2851e+00,  ..., -1.0080e+00,\n",
            "          -4.6946e+00,  6.2303e+00],\n",
            "         [-7.2041e+00, -3.8327e+00, -5.2023e+00,  ...,  1.1681e+00,\n",
            "          -1.5961e+00, -1.0990e-01],\n",
            "         [-6.2278e+00, -4.5997e+00, -4.1856e+00,  ..., -4.5869e-01,\n",
            "          -4.9862e+00,  5.5000e+00]],\n",
            "\n",
            "        [[-7.1497e+00, -5.1568e+00, -7.1580e+00,  ..., -2.8499e+00,\n",
            "          -9.2625e-01,  6.2338e+00],\n",
            "         [-8.3714e+00, -5.2705e+00, -7.2493e+00,  ..., -1.7496e+00,\n",
            "          -3.5310e+00,  8.1561e+00],\n",
            "         [-9.8570e+00, -5.2158e+00, -8.1329e+00,  ..., -6.9026e-01,\n",
            "          -2.7578e+00,  6.3544e+00],\n",
            "         ...,\n",
            "         [-9.0187e+00, -6.4626e+00, -6.5892e+00,  ..., -1.6565e+00,\n",
            "          -4.4329e+00,  7.8542e+00],\n",
            "         [-2.2381e-01, -1.7049e-01, -2.1061e-01,  ...,  2.0648e-02,\n",
            "          -6.7388e-03,  7.9948e-02],\n",
            "         [-2.2381e-01, -1.7049e-01, -2.1061e-01,  ...,  2.0648e-02,\n",
            "          -6.7388e-03,  7.9948e-02]],\n",
            "\n",
            "        [[-7.6092e+00, -5.0716e+00, -7.4063e+00,  ..., -1.1036e+00,\n",
            "          -6.8557e-01,  4.7570e+00],\n",
            "         [-1.0154e+01, -6.5273e+00, -9.1238e+00,  ...,  1.0689e+00,\n",
            "          -8.4719e-01,  4.5475e+00],\n",
            "         [-1.1921e+01, -7.6579e+00, -1.0172e+01,  ...,  2.1254e+00,\n",
            "          -3.8629e-01,  3.1692e+00],\n",
            "         ...,\n",
            "         [-2.2381e-01, -1.7049e-01, -2.1061e-01,  ...,  2.0648e-02,\n",
            "          -6.7388e-03,  7.9948e-02],\n",
            "         [-2.2381e-01, -1.7049e-01, -2.1061e-01,  ...,  2.0648e-02,\n",
            "          -6.7388e-03,  7.9948e-02],\n",
            "         [-2.2381e-01, -1.7049e-01, -2.1061e-01,  ...,  2.0648e-02,\n",
            "          -6.7388e-03,  7.9948e-02]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-7.3610e+00, -5.9825e+00, -6.6768e+00,  ..., -3.4488e+00,\n",
            "          -3.5993e+00,  1.1464e+01],\n",
            "         [-2.2381e-01, -1.7049e-01, -2.1061e-01,  ...,  2.0648e-02,\n",
            "          -6.7388e-03,  7.9948e-02],\n",
            "         [-2.2381e-01, -1.7049e-01, -2.1061e-01,  ...,  2.0648e-02,\n",
            "          -6.7388e-03,  7.9948e-02],\n",
            "         ...,\n",
            "         [-2.2381e-01, -1.7049e-01, -2.1061e-01,  ...,  2.0648e-02,\n",
            "          -6.7388e-03,  7.9948e-02],\n",
            "         [-2.2381e-01, -1.7049e-01, -2.1061e-01,  ...,  2.0648e-02,\n",
            "          -6.7388e-03,  7.9948e-02],\n",
            "         [-2.2381e-01, -1.7049e-01, -2.1061e-01,  ...,  2.0648e-02,\n",
            "          -6.7388e-03,  7.9948e-02]],\n",
            "\n",
            "        [[-7.3609e+00, -5.9825e+00, -6.6768e+00,  ..., -3.4488e+00,\n",
            "          -3.5993e+00,  1.1464e+01],\n",
            "         [-2.2381e-01, -1.7049e-01, -2.1061e-01,  ...,  2.0648e-02,\n",
            "          -6.7388e-03,  7.9948e-02],\n",
            "         [-2.2381e-01, -1.7049e-01, -2.1061e-01,  ...,  2.0648e-02,\n",
            "          -6.7388e-03,  7.9948e-02],\n",
            "         ...,\n",
            "         [-2.2381e-01, -1.7049e-01, -2.1061e-01,  ...,  2.0648e-02,\n",
            "          -6.7388e-03,  7.9948e-02],\n",
            "         [-2.2381e-01, -1.7049e-01, -2.1061e-01,  ...,  2.0648e-02,\n",
            "          -6.7388e-03,  7.9948e-02],\n",
            "         [-2.2381e-01, -1.7049e-01, -2.1061e-01,  ...,  2.0648e-02,\n",
            "          -6.7388e-03,  7.9948e-02]],\n",
            "\n",
            "        [[-7.3610e+00, -5.9825e+00, -6.6768e+00,  ..., -3.4488e+00,\n",
            "          -3.5993e+00,  1.1464e+01],\n",
            "         [-2.2381e-01, -1.7049e-01, -2.1061e-01,  ...,  2.0648e-02,\n",
            "          -6.7388e-03,  7.9948e-02],\n",
            "         [-2.2381e-01, -1.7049e-01, -2.1061e-01,  ...,  2.0648e-02,\n",
            "          -6.7388e-03,  7.9948e-02],\n",
            "         ...,\n",
            "         [-2.2381e-01, -1.7049e-01, -2.1061e-01,  ...,  2.0648e-02,\n",
            "          -6.7388e-03,  7.9948e-02],\n",
            "         [-2.2381e-01, -1.7049e-01, -2.1061e-01,  ...,  2.0648e-02,\n",
            "          -6.7388e-03,  7.9948e-02],\n",
            "         [-2.2381e-01, -1.7049e-01, -2.1061e-01,  ...,  2.0648e-02,\n",
            "          -6.7388e-03,  7.9948e-02]]])\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      B-MISC       0.00      0.00      0.00         4\n",
            "       I-LOC       0.84      0.79      0.82      2094\n",
            "      I-MISC       0.88      0.69      0.78      1264\n",
            "       I-ORG       0.79      0.67      0.73      2092\n",
            "       I-PER       0.91      0.70      0.79      3149\n",
            "           O       0.96      0.99      0.98     42975\n",
            "\n",
            "    accuracy                           0.95     51578\n",
            "   macro avg       0.73      0.64      0.68     51578\n",
            "weighted avg       0.94      0.95      0.94     51578\n",
            "\n",
            "\n",
            "Top Misclassification Patterns:\n",
            "I-PER -> O: 774 times\n",
            "I-ORG -> O: 458 times\n",
            "I-MISC -> O: 298 times\n",
            "I-LOC -> O: 249 times\n",
            "I-LOC -> I-ORG: 148 times\n",
            "I-ORG -> I-LOC: 114 times\n",
            "O -> I-ORG: 112 times\n",
            "O -> I-PER: 106 times\n",
            "I-PER -> I-ORG: 82 times\n",
            "I-ORG -> I-PER: 78 times\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Fgo7Vm4sz1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tOfylO5tszpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) BiLSTM CRF Model"
      ],
      "metadata": {
        "id": "OCaIE9rao8oQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1) BiLSTM CRF Model Architecture"
      ],
      "metadata": {
        "id": "fA4n7-zYtGpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTM_CRF(nn.Module):\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim=100,\n",
        "                 hidden_dim=128, num_lstm_layers=1, dropout=0.5):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "        # Word embeddings layer\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # BiLSTM layer\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                           num_layers=num_lstm_layers,\n",
        "                           bidirectional=True,\n",
        "                           dropout=dropout if num_lstm_layers > 1 else 0,\n",
        "                           batch_first=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters\n",
        "        # transitions[i,j] is the score of transitioning from j to i\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce constraints on the transition parameters\n",
        "        self.transitions.data[tag_to_ix['START'], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix['STOP']] = -10000\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Ensure forward_var is on the same device as feats\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(feats.device)\n",
        "        init_alphas[0][self.tag_to_ix['START']] = 0.\n",
        "\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        for feat in feats:\n",
        "            alphas_t = []\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                emit_score = feat[next_tag].view(1, -1).expand(1, self.tagset_size)\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                alphas_t.append(torch.logsumexp(next_tag_var, dim=1).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix['STOP']]\n",
        "        return torch.logsumexp(terminal_var, dim=1)\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Ensure tags are on the same device as feats\n",
        "        score = torch.zeros(1, device=feats.device)\n",
        "        start_tag = torch.tensor([self.tag_to_ix['START']], dtype=torch.long, device=tags.device)\n",
        "        tags = torch.cat([start_tag, tags])\n",
        "\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix['STOP'], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Ensure initial variables are on the same device as feats\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000., device=feats.device)\n",
        "        init_vvars[0][self.tag_to_ix['START']] = 0\n",
        "\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []\n",
        "            viterbivars_t = []\n",
        "\n",
        "            # Ensure transitions are on the same device\n",
        "            transitions = self.transitions.to(feats.device)\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                next_tag_var = forward_var + transitions[next_tag]\n",
        "                best_tag_id = torch.argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        terminal_var = forward_var + transitions[self.tag_to_ix['STOP']]\n",
        "        best_tag_id = torch.argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix['START']\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags, lengths):\n",
        "        # Get BiLSTM features\n",
        "        embeds = self.word_embeds(sentence)\n",
        "        embeds = self.dropout(embeds)\n",
        "\n",
        "        packed_embeds = pack_padded_sequence(embeds, lengths,\n",
        "                                        batch_first=True,\n",
        "                                        enforce_sorted=False)\n",
        "\n",
        "        packed_lstm_out, _ = self.lstm(packed_embeds)\n",
        "        lstm_out, _ = pad_packed_sequence(packed_lstm_out, batch_first=True)\n",
        "\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "\n",
        "        # Calculate loss for the batch\n",
        "        total_loss = torch.zeros(1, device=sentence.device)\n",
        "        for i, length in enumerate(lengths):\n",
        "            feats = lstm_feats[i][:length]\n",
        "            forward_score = self._forward_alg(feats)\n",
        "            gold_score = self._score_sentence(feats, tags[i][:length])\n",
        "            total_loss += forward_score - gold_score\n",
        "\n",
        "        return total_loss / len(lengths)\n",
        "\n",
        "    def forward(self, sentence, lengths):\n",
        "        # Get BiLSTM features\n",
        "        embeds = self.word_embeds(sentence)\n",
        "        packed_embeds = pack_padded_sequence(embeds, lengths,\n",
        "                                           batch_first=True,\n",
        "                                           enforce_sorted=False)\n",
        "\n",
        "        packed_lstm_out, _ = self.lstm(packed_embeds)\n",
        "        lstm_out, _ = pad_packed_sequence(packed_lstm_out, batch_first=True)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "\n",
        "        # Find the best path for the batch\n",
        "        all_paths = []\n",
        "        all_scores = []\n",
        "        for i, length in enumerate(lengths):\n",
        "            feats = lstm_feats[i][:length]\n",
        "            score, path = self._viterbi_decode(feats)\n",
        "            all_paths.append(path)\n",
        "            all_scores.append(score)\n",
        "\n",
        "        return all_scores, all_paths"
      ],
      "metadata": {
        "id": "TloTh9QEPBS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2) BiLSTM CRF Model Training Infrastructure\n"
      ],
      "metadata": {
        "id": "BypLgCPqO_eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_sequence(seq, to_ix):\n",
        "    return torch.tensor([to_ix[w] for w in seq], dtype=torch.long)\n",
        "\n",
        "# Training function\n",
        "def train_bilstmcrf_model(model, train_data, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for sentence, tags in train_data:\n",
        "            # Clear gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Get the lengths of sequences in batch\n",
        "            lengths = [len(s) for s in sentence]\n",
        "\n",
        "            # Prepare input\n",
        "            sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "            targets = prepare_sequence(tags, tag_to_ix)\n",
        "\n",
        "            # Forward pass\n",
        "            loss = model.neg_log_likelihood(sentence_in, targets, lengths)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Loss: {total_loss/len(train_data):.4f}')"
      ],
      "metadata": {
        "id": "EfIk9NTopGks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bilstmcrf_epoch(model, train_loader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_sentences, batch_tags, lengths in train_loader:\n",
        "        # Move to device\n",
        "        batch_sentences = batch_sentences.to(device)\n",
        "        batch_tags = batch_tags.to(device)\n",
        "\n",
        "        # Clear gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = model.neg_log_likelihood(batch_sentences, batch_tags, lengths)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "# New evaluation function\n",
        "def evaluate_bilstmcrf(model, val_loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_sentences, batch_tags, lengths in val_loader:\n",
        "            # Move to device\n",
        "            batch_sentences = batch_sentences.to(device)\n",
        "            batch_tags = batch_tags.to(device)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = model.neg_log_likelihood(batch_sentences, batch_tags, lengths)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(val_loader)\n",
        "\n",
        "# Modified collate function to handle CRF requirements\n",
        "def create_collate_fn(word2idx, tag2idx):\n",
        "    def collate_fn_bilstmcrf(batch):\n",
        "        # Unpack only sentences and tags\n",
        "        sentences = [item[0] for item in batch]\n",
        "        tags = [item[1] for item in batch]\n",
        "\n",
        "        # Sort batch by sequence length (required for packed sequences)\n",
        "        sorted_indices = sorted(range(len(sentences)),\n",
        "                                key=lambda k: len(sentences[k]),\n",
        "                                reverse=True)\n",
        "\n",
        "        sentences = [sentences[i] for i in sorted_indices]\n",
        "        tags = [tags[i] for i in sorted_indices]\n",
        "\n",
        "        # Get sequence lengths\n",
        "        lengths = [len(s) for s in sentences]\n",
        "\n",
        "        # Pad sequences\n",
        "        padded_sentences = pad_sequence([torch.tensor(s) for s in sentences],\n",
        "                                        batch_first=True,\n",
        "                                        padding_value=word2idx['<PAD>'])\n",
        "        padded_tags = pad_sequence([torch.tensor(t) for t in tags],\n",
        "                                   batch_first=True,\n",
        "                                   padding_value=tag2idx['<PAD>'])\n",
        "\n",
        "        return padded_sentences, padded_tags, lengths\n",
        "\n",
        "    return collate_fn_bilstmcrf\n"
      ],
      "metadata": {
        "id": "NVXQA1ILPshf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Download and Load Data\n",
        "    train_path, val_path, test_path = download_conll2003()\n",
        "    train_sentences, train_tags = load_dataset(train_path)\n",
        "    val_sentences, val_tags = load_dataset(val_path)\n",
        "\n",
        "    # Build Vocabularies\n",
        "    word2idx = build_vocab(train_sentences)\n",
        "    # Need to add START and STOP tags for CRF\n",
        "    tags = sorted(set(tag for tags in train_tags for tag in tags))\n",
        "    tag2idx = {\n",
        "        'START': 0,\n",
        "        'STOP': 1,\n",
        "        '<PAD>': 2\n",
        "    }\n",
        "    tag2idx.update({tag: idx + 3 for idx, tag in enumerate(tags)})\n",
        "\n",
        "    # Create Dataset\n",
        "    train_dataset = NERDataset(train_sentences, train_tags, word2idx, tag2idx)\n",
        "    val_dataset = NERDataset(val_sentences, val_tags, word2idx, tag2idx)\n",
        "\n",
        "    # Create Dataloaders\n",
        "    collate_fn_bilstmcrf = create_collate_fn(word2idx, tag2idx)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn_bilstmcrf)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn_bilstmcrf)\n",
        "\n",
        "    # Model\n",
        "    model = BiLSTM_CRF(  # Changed from BiLSTM to BiLSTM_CRF\n",
        "        vocab_size=len(word2idx),\n",
        "        tag_to_ix=tag2idx,  # Changed from num_tags to tag_to_ix\n",
        "        embedding_dim=100,\n",
        "        hidden_dim=256,\n",
        "        num_lstm_layers=1,\n",
        "        dropout=0.5\n",
        "    )\n",
        "\n",
        "    # Setup Training\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    # Remove criterion as CRF handles loss calculation\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "    # Training Loop\n",
        "    num_epochs = 10\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train_bilstmcrf_epoch(model, train_loader, optimizer, device)\n",
        "        val_loss = evaluate_bilstmcrf(model, val_loader, device)\n",
        "        print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'word2idx': word2idx,\n",
        "        'tag2idx': tag2idx\n",
        "    }, \"bilstmcrf_ner_model\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "lCBPmk_WlIco",
        "outputId": "8beb144b-4738-4005-a2e7-07b9965b8c49",
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-2120becde2d1>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-2120becde2d1>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Download and Load Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_conll2003\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mval_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-1afd88ac2c74>\u001b[0m in \u001b[0;36mdownload_conll2003\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{base_url}{file}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    790\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3) Benchmarking Functions\n"
      ],
      "metadata": {
        "id": "pX437HTqmN2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "import numpy as np\n",
        "from typing import List, Tuple, Dict\n",
        "import logging"
      ],
      "metadata": {
        "id": "6wT3s-uFmV2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.DEBUG)"
      ],
      "metadata": {
        "id": "jnuY6339vYYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def benchmark_model(model, dataloader, word2idx, tag2idx, idx2tag, device):\n",
        "    \"\"\"\n",
        "    Benchmark the NER model and return comprehensive metrics\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "    # Collect true and predicted labels\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "    print_model_output = True\n",
        "    with torch.no_grad():\n",
        "        for batch_sentences, batch_tags, lengths in dataloader:\n",
        "            batch_sentences = batch_sentences.to(device)\n",
        "            batch_tags = batch_tags.to(device)\n",
        "\n",
        "            # Get predictions\n",
        "            # logging.debug(type(batch_sentences))\n",
        "            # model_output = model(batch_sentences, lengths)\n",
        "            ####\n",
        "            model_output = torch.tensor(model(batch_sentences, lengths)[0])\n",
        "            ####\n",
        "            if print_model_output:\n",
        "                logging.debug(f\"{len(batch_sentences)}, batch_sentences: {batch_sentences}\")\n",
        "                logging.debug(f\"{len(batch_tags)}, batch_tag: {batch_tags}\")\n",
        "                logging.debug(f\"{len(lengths)}, lengths: {lengths}\")\n",
        "                logging.debug(f\"{len(model_output)}, model_output: {model_output}\")\n",
        "                print_model_output = False\n",
        "\n",
        "            # If model returns a list, extract the tag scores\n",
        "            if isinstance(model_output, list):\n",
        "                logging.debug(\"model_output is a list\")\n",
        "                # Try different common list indexing patterns\n",
        "                if len(model_output) == 2:\n",
        "                    # Common pattern: [loss, tag_scores] or [hidden_states, tag_scores]\n",
        "                    tag_scores = model_output[1]\n",
        "                elif len(model_output) > 2:\n",
        "                    # If more than 2 elements, try the first two\n",
        "                    tag_scores = model_output[0]  # or model_output[1]\n",
        "                else:\n",
        "                    # Fallback to first element if only one other element exists\n",
        "                    tag_scores = model_output[0]\n",
        "            else:\n",
        "                logging.debug(f\"model_output is not a list. It is a {type(model_output)}\")\n",
        "                tag_scores = model_output\n",
        "\n",
        "            # Ensure tag_scores is a tensor\n",
        "            if not isinstance(tag_scores, torch.Tensor):\n",
        "                # logging.debug(model_output)\n",
        "                # logging.debug(tag_scores)\n",
        "                # Add debug print to understand the structure\n",
        "                print(\"Model output:\", model_output)\n",
        "                print(\"Tag scores:\", tag_scores)\n",
        "                raise TypeError(f\"Expected tag_scores to be a tensor, but got {type(tag_scores)}\")\n",
        "\n",
        "            logging.debug(f\"{len(tag_scores)}, tag_scores: {tag_scores}\")\n",
        "            predictions = torch.argmax(tag_scores, dim=0)\n",
        "            logging.debug(predictions)\n",
        "\n",
        "            # Process batch\n",
        "            for i in range(len(lengths)):\n",
        "                seq_len = lengths[i]\n",
        "                true_labels.extend(batch_tags[i, :seq_len].cpu().numpy())\n",
        "                pred_labels.extend(predictions[i].cpu().numpy())\n",
        "\n",
        "    # Dynamically get unique labels from true and predicted labels\n",
        "    unique_labels = sorted(list(set(true_labels) | set(pred_labels)))\n",
        "    unique_target_names = [idx2tag[label] for label in unique_labels]\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(\n",
        "        true_labels,\n",
        "        pred_labels,\n",
        "        labels=unique_labels,\n",
        "        target_names=unique_target_names,\n",
        "        zero_division=0\n",
        "    )\n",
        "\n",
        "    return true_labels, pred_labels, report"
      ],
      "metadata": {
        "id": "DofiSTu4mQCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_confusion_matrix(true_labels, pred_labels, idx2tag):\n",
        "    \"\"\"\n",
        "    Create and save a confusion matrix visualization\n",
        "    \"\"\"\n",
        "    # Get unique labels\n",
        "    unique_labels = sorted(list(set(true_labels) | set(pred_labels)))\n",
        "\n",
        "    # Create confusion matrix\n",
        "    cm = confusion_matrix(true_labels, pred_labels, labels=unique_labels)\n",
        "\n",
        "    # Get tag names for unique labels\n",
        "    tag_names = [idx2tag[label] for label in unique_labels]\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=tag_names,\n",
        "                yticklabels=tag_names)\n",
        "    plt.title('Confusion Matrix for NER Model')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('ner_confusion_matrix.png')\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "RTO18dhtmmqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detailed_error_analysis(true_labels, pred_labels, idx2tag):\n",
        "    \"\"\"\n",
        "    Perform detailed error analysis\n",
        "    \"\"\"\n",
        "    # Identify misclassified instances\n",
        "    misclassified = []\n",
        "    for true, pred in zip(true_labels, pred_labels):\n",
        "        if true != pred:\n",
        "            misclassified.append({\n",
        "                'true_label': idx2tag[true],\n",
        "                'pred_label': idx2tag[pred]\n",
        "            })\n",
        "\n",
        "    # Aggregate misclassification stats\n",
        "    error_counts = {}\n",
        "    for error in misclassified:\n",
        "        key = f\"{error['true_label']} -> {error['pred_label']}\"\n",
        "        error_counts[key] = error_counts.get(key, 0) + 1\n",
        "\n",
        "    # Sort errors by frequency\n",
        "    sorted_errors = sorted(error_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Print top errors\n",
        "    print(\"\\nTop Misclassification Patterns:\")\n",
        "    for error, count in sorted_errors[:10]:\n",
        "        print(f\"{error}: {count} times\")\n",
        "\n",
        "    return misclassified, sorted_errors"
      ],
      "metadata": {
        "id": "LgkgWL8xml2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4) Loading the model"
      ],
      "metadata": {
        "id": "gFyDkzWfnc9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_bilstm_crf_model(path):\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(path, map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "    # Extract vocabularies\n",
        "    word2idx = checkpoint['word2idx']\n",
        "    tag2idx = checkpoint['tag2idx']\n",
        "\n",
        "    # Create reverse tag mapping\n",
        "    idx2tag = {idx: tag for tag, idx in tag2idx.items()}\n",
        "\n",
        "    # Initialize model with same parameters as during training\n",
        "    model = BiLSTM_CRF(\n",
        "        vocab_size=len(word2idx),\n",
        "        tag_to_ix=tag2idx,\n",
        "        embedding_dim=100,  # Ensure these match your training config\n",
        "        hidden_dim=256,\n",
        "        num_lstm_layers=1,\n",
        "        dropout=0.5\n",
        "    )\n",
        "\n",
        "    # Load model state\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.to(device)\n",
        "    model.eval()  # Set to evaluation mode\n",
        "\n",
        "    return model, word2idx, tag2idx, idx2tag"
      ],
      "metadata": {
        "id": "iXF8oqLgfeGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5) Benchmarking and Results"
      ],
      "metadata": {
        "id": "91lz1oDptiJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Load model and data\n",
        "    model, word2idx, tag2idx, idx2tag = load_bilstm_crf_model(path= \"bilstmcrf_ner_model\")\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Load test data\n",
        "    _, test_path, _ = download_conll2003()\n",
        "    test_sentences, test_tags = load_dataset(test_path)\n",
        "\n",
        "    # Create test dataset\n",
        "    test_dataset = NERDataset(test_sentences, test_tags, word2idx, tag2idx)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    # Benchmark model\n",
        "    true_labels, pred_labels, report = benchmark_model(\n",
        "        model, test_loader, word2idx, tag2idx, idx2tag, device\n",
        "    )\n",
        "\n",
        "    # Print classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(report)\n",
        "\n",
        "    # Visualize confusion matrix\n",
        "    visualize_confusion_matrix(true_labels, pred_labels, tag2idx, idx2tag)\n",
        "\n",
        "    # Perform error analysis\n",
        "    misclassified, sorted_errors = detailed_error_analysis(\n",
        "        true_labels, pred_labels, idx2tag\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "id": "0fDzHGWvndP0",
        "outputId": "b92a1d50-704c-4ea0-8056-38e52e9408c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-44-0810b7e27ee0>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(path, map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
            "DEBUG:root:32, batch_sentences: tensor([[  300,    42,  2275,  ...,   790,  2252,    11],\n",
            "        [ 4922,    42,  1721,  ...,    11,     0,     0],\n",
            "        [ 1767, 13976,  2196,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [    2,     0,     0,  ...,     0,     0,     0],\n",
            "        [    2,     0,     0,  ...,     0,     0,     0],\n",
            "        [    2,     0,     0,  ...,     0,     0,     0]])\n",
            "DEBUG:root:32, batch_tag: tensor([[10, 10,  6,  ..., 10,  8, 10],\n",
            "        [10, 10, 10,  ..., 10,  0,  0],\n",
            "        [10, 10,  8,  ...,  0,  0,  0],\n",
            "        ...,\n",
            "        [10,  0,  0,  ...,  0,  0,  0],\n",
            "        [10,  0,  0,  ...,  0,  0,  0],\n",
            "        [10,  0,  0,  ...,  0,  0,  0]])\n",
            "DEBUG:root:32, lengths: (41, 39, 38, 37, 35, 35, 34, 34, 31, 30, 30, 28, 27, 26, 25, 25, 25, 24, 22, 18, 14, 13, 12, 11, 9, 7, 7, 2, 2, 1, 1, 1)\n",
            "DEBUG:root:32, model_output: tensor([306.6231, 291.8260, 253.7307, 241.2749, 246.9803, 217.0444, 228.5528,\n",
            "        259.9489, 178.5724, 201.3711, 152.4286, 190.0543, 139.5292, 156.9074,\n",
            "        163.1107, 135.9857, 131.7395, 165.7628, 151.5768,  85.9319,  99.8517,\n",
            "         61.8053,  71.0276,  49.3628,  49.0678,  37.3294,  43.0317,  10.0868,\n",
            "         10.0868,   7.4678,   7.4678,   7.4678])\n",
            "DEBUG:root:model_output is not a list. It is a <class 'torch.Tensor'>\n",
            "DEBUG:root:32, tag_scores: tensor([306.6231, 291.8260, 253.7307, 241.2749, 246.9803, 217.0444, 228.5528,\n",
            "        259.9489, 178.5724, 201.3711, 152.4286, 190.0543, 139.5292, 156.9074,\n",
            "        163.1107, 135.9857, 131.7395, 165.7628, 151.5768,  85.9319,  99.8517,\n",
            "         61.8053,  71.0276,  49.3628,  49.0678,  37.3294,  43.0317,  10.0868,\n",
            "         10.0868,   7.4678,   7.4678,   7.4678])\n",
            "DEBUG:root:tensor(0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-8824b120200c>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-98-8824b120200c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Benchmark model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     true_labels, pred_labels, report = benchmark_model(\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag2idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx2tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     )\n",
            "\u001b[0;32m<ipython-input-97-9aff4a66c0e6>\u001b[0m in \u001b[0;36mbenchmark_model\u001b[0;34m(model, dataloader, word2idx, tag2idx, idx2tag, device)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mtrue_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_tags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0mpred_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# Dynamically get unique labels from true and predicted labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "X11qH4aYCez6",
        "outputId": "6fbdd23c-71a8-4304-be6d-3fc378c89c90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    }
  ]
}